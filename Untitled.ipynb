{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency parsing baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Dependency parsing is the task of mapping a sentence to a formal representation of its syntactic structure in the form of a dependency tree, which consists of directed arcs between individual words (tokens). Here we will implement a dependency parser baseline based on the arc-standard algorithm and the fixed-window model that we implemented in Lab L3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchify import *\n",
    "from create_vocab import *\n",
    "from data_handling import *\n",
    "from parser import *\n",
    "from projectivize import *\n",
    "from uas import *\n",
    "from window_models import *\n",
    "from taggers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hugo/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: Unexpected error from cudaGetDeviceCount(). Did you run some cuda functions before calling NumCudaDevices() that might have already set an error? Error 804: forward compatibility was attempted on non supported HW (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset('data/en_gum-ud-train-projectivized.conllu')\n",
    "dev_data = Dataset('data/en_gum-ud-dev-projectivized.conllu')\n",
    "test_data = Dataset('data/en_gum-ud-test-projectivized.conllu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_fixed_window(train_data, n_epochs=2, batch_size=100, lr=1e-2):\n",
    "    vocab_words, vocab_tags = make_vocabs(train_data)\n",
    "    tagger = FixedWindowTagger(vocab_words, vocab_tags, len(vocab_tags))\n",
    "    \n",
    "    optimizer = optim.Adam(tagger.model.parameters(), lr=lr)\n",
    "    for i in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        batch_nr = 0\n",
    "        for x, y in training_examples_tagger(vocab_words, vocab_tags, train_data, tagger):\n",
    "            batch_nr += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = tagger.model.forward(x)\n",
    "            \n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            if batch_nr % 100 == 1:\n",
    "                print(total_loss/batch_nr)\n",
    "                #pass\n",
    "    return tagger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9665334224700928\n",
      "1.0812707528619483\n",
      "0.7790257898136158\n",
      "0.6482286219581022\n",
      "0.5718291947557742\n",
      "0.5247587634328597\n",
      "0.4937145939831329\n",
      "0.4742310242288973\n",
      "0.4528300589445825\n",
      "0.389119952917099\n",
      "0.19247261729865972\n",
      "0.1533693371118227\n",
      "0.134713521403604\n",
      "0.13226546850659307\n",
      "0.13156073175355823\n",
      "0.12804667915321402\n",
      "0.12624715518581012\n",
      "0.12659532848231672\n"
     ]
    }
   ],
   "source": [
    "tagger = train_fixed_window(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8579923882017126"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(tagger, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "def train_fixed_parser(train_data, n_epochs=2, batch_size=100, lr=1e-2):\n",
    "    vocab_words, vocab_tags = make_vocabs(train_data)\n",
    "    parser = FixedWindowParser(vocab_words, vocab_tags)\n",
    "    \n",
    "    optimizer = optim.Adam(parser.model.parameters(), lr=lr)\n",
    "    for i in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        batch_nr = 0\n",
    "        for x, y in training_examples_parser(vocab_words, vocab_tags, train_data, parser):\n",
    "            batch_nr += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = parser.model.forward(x)\n",
    "            \n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            if batch_nr % 100 == 1:\n",
    "                print(total_loss/batch_nr)\n",
    "                \n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1036105155944824\n",
      "0.5465295311838093\n",
      "0.4689012935653848\n",
      "0.4354865457924498\n",
      "0.41512257559341087\n",
      "0.39950304402562675\n",
      "0.37756019548052755\n",
      "0.3639137398414367\n",
      "0.3479195310409819\n",
      "0.342186158090896\n",
      "0.3355889265182671\n",
      "0.33331573097801664\n",
      "0.3316898877754944\n",
      "0.3321779999827578\n",
      "0.3323586756425998\n",
      "0.3299915258866362\n",
      "0.3261929063346332\n",
      "0.33608385920524597\n",
      "0.27702895824862\n",
      "0.25688556088736997\n",
      "0.24455007403296886\n",
      "0.23824417407152956\n",
      "0.23168013610704216\n",
      "0.2179583643877665\n",
      "0.21280773544681394\n",
      "0.20715550654747997\n",
      "0.20640692229462285\n",
      "0.20554061106812735\n",
      "0.20562694493180428\n",
      "0.20534269297751384\n",
      "0.20602822875379256\n",
      "0.20649214553514456\n",
      "0.20577795108188338\n",
      "0.20514838681204348\n"
     ]
    }
   ],
   "source": [
    "parser = train_fixed_parser(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64831093808866"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uas(parser, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_uas_with_tagger_preds(tagger, parser, data):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    new_data = []\n",
    "    for sent in data:\n",
    "        pred_tags = tagger.predict(sent)\n",
    "    \n",
    "        # Replace gold tags with predicted\n",
    "        for i , (_, tag) in enumerate(pred_tags):\n",
    "            sent[i] = (sent[i][0], tag, sent[i][2])\n",
    "        new_data.append(sent)\n",
    "        \n",
    "    return uas(parser, new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5930553811377621"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_uas_with_tagger_preds(tagger, parser, test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
