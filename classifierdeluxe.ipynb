{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency parsing baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Dependency parsing is the task of mapping a sentence to a formal representation of its syntactic structure in the form of a dependency tree, which consists of directed arcs between individual words (tokens). Here we will implement a dependency parser baseline based on the arc-standard algorithm and the fixed-window model that we implemented in Lab L3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchify import *\n",
    "from create_vocab import *\n",
    "from data_handling import *\n",
    "from parser import *\n",
    "from projectivize import *\n",
    "from uas import *\n",
    "from window_models import *\n",
    "from taggers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset('./data/en_gum-ud-train-projectivized.conllu')\n",
    "dev_data = Dataset('./data/en_gum-ud-dev-projectivized.conllu')\n",
    "test_data = Dataset('./data/en_gum-ud-test-projectivized.conllu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_fixed_window(train_data, n_epochs=2, batch_size=100, lr=1e-3):\n",
    "    vocab_words, vocab_tags = make_vocabs(train_data)\n",
    "    tagger = FixedWindowTagger(vocab_words, vocab_tags, len(vocab_tags))\n",
    "    \n",
    "    optimizer = optim.Adam(tagger.model.parameters(), lr=lr)\n",
    "    for i in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        batch_nr = 0\n",
    "        for x, y in training_examples_tagger(vocab_words, vocab_tags, train_data, tagger):\n",
    "            batch_nr += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = tagger.model.forward(x)\n",
    "            \n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            if batch_nr % 100 == 1:\n",
    "                print(total_loss/batch_nr)\n",
    "                #pass\n",
    "    return tagger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9685540199279785\n",
      "2.3825770805377773\n",
      "1.815235838664705\n",
      "1.4485517878865086\n",
      "1.2125645115265524\n",
      "1.0670260203158308\n",
      "0.9569959682900576\n",
      "0.8841368622131933\n",
      "0.8198371470048931\n",
      "0.5263502597808838\n",
      "0.2880955667483925\n",
      "0.25445233796959493\n",
      "0.22974832894348624\n",
      "0.21985018116763405\n",
      "0.21230887778534624\n",
      "0.2024515613095336\n",
      "0.19645805638310063\n",
      "0.19186879511220328\n"
     ]
    }
   ],
   "source": [
    "tagger = train_fixed_window(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8846905139787572"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(tagger, dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "def train_fixed_parser(train_data, n_epochs=3, batch_size=100, lr=1e-3):\n",
    "    vocab_words, vocab_tags = make_vocabs(train_data)\n",
    "    parser = FixedWindowParser(vocab_words, vocab_tags)\n",
    "    \n",
    "    optimizer = optim.Adam(parser.model.parameters(), lr=lr)\n",
    "    for i in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        batch_nr = 0\n",
    "        for x, y in training_examples_parser(vocab_words, vocab_tags, train_data, parser):\n",
    "            batch_nr += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = parser.model.forward(x)\n",
    "            \n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            if batch_nr % 100 == 1:\n",
    "                print(total_loss/batch_nr)\n",
    "                \n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3895262479782104\n",
      "0.975690499390706\n",
      "0.826820241426354\n",
      "0.7343247677400658\n",
      "0.6786869084299948\n",
      "0.6332944770773014\n",
      "0.6022871892880679\n",
      "0.5780175194122992\n",
      "0.5587399612912227\n",
      "0.5438054190921731\n",
      "0.5308842497629362\n",
      "0.5193402110772388\n",
      "0.5087740350697658\n",
      "0.5009557470095148\n",
      "0.4935720121643528\n",
      "0.48423793569435525\n",
      "0.47475677231637337\n",
      "0.4661284290179654\n",
      "0.459025665695703\n",
      "0.4538143041971356\n",
      "0.44697732341730373\n",
      "0.43955135329855677\n",
      "0.43345202805507405\n",
      "0.4310107293114979\n",
      "0.4292923091526381\n",
      "0.42606381785983993\n",
      "0.4229723537560611\n",
      "0.4199600121332557\n",
      "0.4173018935667494\n",
      "0.41431059093516026\n",
      "0.4129874807587269\n",
      "0.41238731051915617\n",
      "0.4108746001535898\n",
      "0.4098496104764671\n",
      "0.4089982012608268\n",
      "0.40748008760689874\n",
      "0.40705859166396985\n",
      "0.40697694239673404\n",
      "0.40496820795343164\n",
      "0.4043519115794075\n",
      "0.40325102238908644\n",
      "0.40163830784915916\n",
      "0.4000097432503443\n",
      "0.3985437331671383\n",
      "0.39758884557686835\n",
      "0.3954571121912536\n",
      "0.3939200635142001\n",
      "0.41952258348464966\n",
      "0.35665053778355665\n",
      "0.35473744986365685\n",
      "0.35410707545438874\n",
      "0.34988350058880235\n",
      "0.3405169012274095\n",
      "0.33464302572603033\n",
      "0.3310954889731638\n",
      "0.32766570202011\n",
      "0.3250058230413713\n",
      "0.32304365993975165\n",
      "0.320242262801509\n",
      "0.3175484444465268\n",
      "0.3159465107903583\n",
      "0.31402678398959216\n",
      "0.3100936696439644\n",
      "0.3062705895808211\n",
      "0.3023510589639381\n",
      "0.29968628975904565\n",
      "0.2989598282684877\n",
      "0.29637656755361896\n",
      "0.29333232226349354\n",
      "0.29101043546920147\n",
      "0.29115751921249855\n",
      "0.29132708117074146\n",
      "0.2904164290151707\n",
      "0.28982348384902096\n",
      "0.288996833101086\n",
      "0.2885928189475721\n",
      "0.2882384659041211\n",
      "0.28812059464652473\n",
      "0.2881799694685273\n",
      "0.2879681717121426\n",
      "0.2878897379394265\n",
      "0.2879744215012122\n",
      "0.2874162704778276\n",
      "0.2875894574105524\n",
      "0.28796373616719817\n",
      "0.2868217434758608\n",
      "0.2868592575883841\n",
      "0.28656899102238886\n",
      "0.2859540100958152\n",
      "0.2855795048996611\n",
      "0.28537066086392243\n",
      "0.2854008658259423\n",
      "0.28451716369922175\n",
      "0.28419876608157957\n",
      "0.23674392700195312\n",
      "0.2699040102929172\n",
      "0.2712101374396044\n",
      "0.274589876795924\n",
      "0.27402660806205803\n",
      "0.2685853391439615\n",
      "0.2641454242207048\n",
      "0.263253531287213\n",
      "0.26088421725750566\n",
      "0.2594852563113669\n",
      "0.25741522008930884\n",
      "0.25529930809957674\n",
      "0.25310205594077395\n",
      "0.2522122139006647\n",
      "0.2505289090160469\n",
      "0.24693620467507624\n",
      "0.24392227719605974\n",
      "0.24084782496156026\n",
      "0.2385215483345236\n",
      "0.23856775454396892\n",
      "0.23701745273172112\n",
      "0.23493836500612342\n",
      "0.2335327844330529\n",
      "0.23393930446863279\n",
      "0.23421484281909014\n",
      "0.23410980919542096\n",
      "0.2340204032959387\n",
      "0.2336943874708682\n",
      "0.23376256486840521\n",
      "0.23419318663040467\n",
      "0.23434125840346123\n",
      "0.23388229191341695\n",
      "0.2339075396220895\n",
      "0.23393509694750617\n",
      "0.23398252209427778\n",
      "0.23327749181444118\n",
      "0.23327370519084886\n",
      "0.2334652937620564\n",
      "0.2323729778568671\n",
      "0.23222197871774594\n",
      "0.23189611163784551\n",
      "0.23150954223393494\n",
      "0.23120348258629012\n",
      "0.23113057454816271\n",
      "0.23127867391054074\n",
      "0.23063298277979002\n",
      "0.23057442927242\n"
     ]
    }
   ],
   "source": [
    "parser = train_fixed_parser(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7809334530067957"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uas(parser, dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('<root>', '<root>', 0), ('However', 'ADV', 6), (',', 'PUNCT', 1), ('it', 'PRON', 6), ('is', 'AUX', 6), ('not', 'PART', 6), ('enough', 'ADJ', 0), ('to', 'PART', 9), ('have', 'AUX', 9), ('attained', 'VERB', 6), ('such', 'ADJ', 12), ('native-like', 'ADJ', 12), ('levels', 'NOUN', 9), ('.', 'PUNCT', 6)]\n"
     ]
    }
   ],
   "source": [
    "for i, data in enumerate(dev_data):\n",
    "    if i == 3:\n",
    "        uas(parser, [data])\n",
    "        print(data)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing parser with predicted tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_uas_with_tagger_preds(tagger, parser, data):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    new_data = []\n",
    "    for sent in data:\n",
    "        pred_tags = tagger.predict(sent)\n",
    "    \n",
    "        # Replace gold tags with predicted\n",
    "        for i , (_, tag) in enumerate(pred_tags):\n",
    "            sent[i] = (sent[i][0], tag, sent[i][2])\n",
    "        new_data.append(sent)\n",
    "        \n",
    "    return uas(parser, new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7137453519682011"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_uas_with_tagger_preds(tagger, parser, dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
