{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependency parsing baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Dependency parsing is the task of mapping a sentence to a formal representation of its syntactic structure in the form of a dependency tree, which consists of directed arcs between individual words (tokens). Here we will implement a dependency parser baseline based on the arc-standard algorithm and the fixed-window model that we implemented in Lab L3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from batchify import *\n",
    "from create_vocab import *\n",
    "from data_handling import *\n",
    "import syntax_parser as parser \n",
    "from projectivize import *\n",
    "from uas import *\n",
    "from window_models import *\n",
    "from taggers import *\n",
    "import importlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset('./data/en_gum-ud-train-projectivized.conllu')\n",
    "dev_data = Dataset('./data/en_gum-ud-dev-projectivized.conllu')\n",
    "test_data = Dataset('./data/en_gum-ud-test-projectivized.conllu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_fixed_window(train_data, n_epochs=1, batch_size=100, lr=1e-2):\n",
    "    vocab_words, vocab_tags = make_vocabs(train_data)\n",
    "    tagger = FixedWindowTagger(vocab_words, vocab_tags, len(vocab_tags))\n",
    "    \n",
    "    optimizer = optim.Adam(tagger.model.parameters(), lr=lr)\n",
    "    for i in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        batch_nr = 0\n",
    "        for x, y in training_examples_tagger(vocab_words, vocab_tags, train_data, tagger):\n",
    "            batch_nr += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = tagger.model.forward(x)\n",
    "            \n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            if batch_nr % 100 == 1:\n",
    "                print(total_loss/batch_nr)\n",
    "                #pass\n",
    "    return tagger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9429187774658203\n",
      "1.0892341899694782\n",
      "0.7818226194500331\n",
      "0.6481780479368181\n",
      "0.5728677407353001\n",
      "0.5280328874370295\n",
      "0.49625149260146445\n",
      "0.47630385712278045\n",
      "0.4555401794993773\n"
     ]
    }
   ],
   "source": [
    "tagger = train_fixed_window(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8839580026858748"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(tagger, dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tqdm as tqdm\n",
    "import time\n",
    "\n",
    "def train_fixed_parser(train_data, n_epochs=10, batch_size=100, lr=1e-3):\n",
    "    vocab_words, vocab_tags = make_vocabs(train_data)\n",
    "    myparser = parser.FixedWindowParser(vocab_words, vocab_tags)\n",
    "    myparser.model.to(device)\n",
    "    myparser.model.train()\n",
    "    optimizer = optim.Adam(myparser.model.parameters(), lr=lr)\n",
    "    \n",
    "    start_time = time.time()\n",
    "    for i in tqdm.tqdm(range(n_epochs)):\n",
    "        total_loss = 0\n",
    "        batch_nr = 0\n",
    "        \n",
    "        if (i != 0):\n",
    "            print(uas(myparser, dev_data))\n",
    "            myparser.model.train()\n",
    "        \n",
    "        for words, tags, i, x, y in training_examples_parser(vocab_words, vocab_tags, train_data, myparser):\n",
    "            words = words.to(device)\n",
    "            tags = tags.to(device)\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            i = i.to(device)\n",
    "\n",
    "            batch_nr += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = myparser.model.forward(words[i], tags[i], x)\n",
    "            \n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        print(\"loss: \", total_loss/batch_nr, \"time was: \", time.time() - start_time)\n",
    "                \n",
    "    return myparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/10 [00:00<?, ?it/s]C:\\Users\\Viktor\\Dropbox\\liu\\TDDE09\\nlp-project\\window_models.py:181: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  feature_ids = torch.tensor(feature_ids)\n",
      " 10%|████████▏                                                                         | 1/10 [04:27<40:11, 268.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.3910942441863437 time was:  267.9992172718048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Viktor\\Dropbox\\liu\\TDDE09\\nlp-project\\syntax_parser.py:152: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred = torch.nn.functional.log_softmax(pred)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7981151429670471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|████████████████▍                                                                 | 2/10 [13:27<46:35, 349.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.2355125615642004 time was:  807.3131680488586\n",
      "0.8283754327477881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|████████████████████████▌                                                         | 3/10 [24:16<51:14, 439.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.16589096630091357 time was:  1456.2568061351776\n",
      "0.8302346454673676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|████████████████████████████████▊                                                 | 4/10 [36:00<51:52, 518.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.12197428298811765 time was:  2160.6432161331177\n",
      "0.8340171816899602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████████████████████████████████████████                                         | 5/10 [47:22<47:18, 567.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.09485078749557509 time was:  2842.331746816635\n",
      "0.8341454032568278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|█████████████████████████████████████████████████▏                                | 6/10 [57:56<39:10, 587.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.07463722783698527 time was:  3476.212389945984\n",
      "0.846005898192076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|████████████████████████████████████████████████████████                        | 7/10 [1:09:43<31:10, 623.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.06048639499960183 time was:  4183.225562810898\n",
      "0.8465828952429799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|████████████████████████████████████████████████████████████████                | 8/10 [1:21:32<21:38, 649.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.049671645806643155 time was:  4892.527213096619\n",
      "0.8457494550583408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|████████████████████████████████████████████████████████████████████████        | 9/10 [1:33:33<11:10, 670.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.04179369712303164 time was:  5613.294797420502\n",
      "0.8444031286062316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 10/10 [1:44:01<00:00, 624.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.03567980632662459 time was:  6241.302361726761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(parser)\n",
    "myparser = train_fixed_parser(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8465187844595461"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uas(myparser, dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8442170036418435"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uas(myparser, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing parser with predicted tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_uas_with_tagger_preds(tagger, _parser, data):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    new_data = []\n",
    "    for sent in data:\n",
    "        pred_tags = tagger.predict(sent)\n",
    "    \n",
    "        # Replace gold tags with predicted\n",
    "        for i , (_, tag) in enumerate(pred_tags):\n",
    "            sent[i] = (sent[i][0], tag, sent[i][2])\n",
    "        new_data.append(sent)\n",
    "        \n",
    "    return uas(_parser, new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7832414412104116"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_uas_with_tagger_preds(tagger, myparser, dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FixedWindowParser' object has no attribute 'state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-56a805e32404>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"~/paper-180-lstm-10-epochs-845acc\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmyparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mPATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'FixedWindowParser' object has no attribute 'state_dict'"
     ]
    }
   ],
   "source": [
    "path = \"~/paper-180-lstm-10-epochs-845acc\"\n",
    "torch.save(myparser.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
