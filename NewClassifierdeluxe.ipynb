{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Classifierdeluxe.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "I0G66EDCpWYh",
        "XE1gR7X_S6dX",
        "LpLw_2wHpq-o",
        "lzAELj15S6dY",
        "nI0pJ_DFpgCw",
        "GxuIFsK7o_7z",
        "KzUx0JQiS6db"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygrwIIZMS6dT"
      },
      "source": [
        "# Dependency parsing baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0Cw9eF2S6dW"
      },
      "source": [
        "\n",
        "Dependency parsing is the task of mapping a sentence to a formal representation of its syntactic structure in the form of a dependency tree, which consists of directed arcs between individual words (tokens). Here we will implement a dependency parser baseline based on the arc-standard algorithm and the fixed-window model that we implemented in Lab L3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0G66EDCpWYh"
      },
      "source": [
        "### Download neccessary python files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5P03qH_bS8y8"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/batchify.py\n",
        "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/create_vocab.py\n",
        "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/data_handling.py\n",
        "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/syntax_parser.py\n",
        "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/projectivize.py\n",
        "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/taggers.py\n",
        "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/uas.py\n",
        "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/window_models.py\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XE1gR7X_S6dX"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUObqPhtS6dX"
      },
      "source": [
        "from batchify import *\n",
        "from create_vocab import *\n",
        "from data_handling import *\n",
        "import syntax_parser as parser \n",
        "from projectivize import *\n",
        "from uas import *\n",
        "from window_models import *\n",
        "from taggers import *\n",
        "import importlib\n"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KGa8T2vS6dX"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hx-dccpMS6dX",
        "outputId": "250540e2-568c-4a63-8881-38bc2e99b27c"
      },
      "source": [
        "device"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am2_wdxqS6dY"
      },
      "source": [
        "## Prepare data set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCBNkXn8pRWP"
      },
      "source": [
        "### Download data files "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JD1e_hg6Tr28"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/data/en_gum-ud-dev-projectivized.conllu\n",
        "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/data/en_gum-ud-train-projectivized.conllu\n",
        "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/data/en_gum-ud-test-projectivized.conllu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TaBlhMVUS6dY"
      },
      "source": [
        "train_data = Dataset('./en_gum-ud-train-projectivized.conllu')\n",
        "dev_data = Dataset('./en_gum-ud-dev-projectivized.conllu')\n",
        "test_data = Dataset('./en_gum-ud-test-projectivized.conllu')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpLw_2wHpq-o"
      },
      "source": [
        "# Tagger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t4pmUeuS6dY"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def train_fixed_window(train_data, n_epochs=1, batch_size=100, lr=1e-2):\n",
        "    vocab_words, vocab_tags = make_vocabs(train_data)\n",
        "    tagger = FixedWindowTagger(vocab_words, vocab_tags, len(vocab_tags))\n",
        "    \n",
        "    optimizer = optim.Adam(tagger.model.parameters(), lr=lr)\n",
        "    for i in range(n_epochs):\n",
        "        total_loss = 0\n",
        "        batch_nr = 0\n",
        "        for x, y in training_examples_tagger(vocab_words, vocab_tags, train_data, tagger):\n",
        "            batch_nr += 1\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            y_pred = tagger.model.forward(x)\n",
        "            \n",
        "            loss = F.cross_entropy(y_pred, y)\n",
        "            loss.backward()\n",
        "            total_loss += loss.item()\n",
        "            optimizer.step()\n",
        "            if batch_nr % 100 == 1:\n",
        "                print(total_loss/batch_nr)\n",
        "                #pass\n",
        "    return tagger\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzAELj15S6dY"
      },
      "source": [
        "## Train tagger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LWBH7yLWS6dY",
        "outputId": "9ab66171-c03f-4bec-cc01-d1b124df661a"
      },
      "source": [
        "tagger = train_fixed_window(train_data)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.941803216934204\n",
            "1.0744318774726132\n",
            "0.7767540175671601\n",
            "0.6463600118393914\n",
            "0.5697921334285094\n",
            "0.5255260007556327\n",
            "0.4930651445381852\n",
            "0.47285652569841896\n",
            "0.4522376473848888\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nI0pJ_DFpgCw"
      },
      "source": [
        "## Eval tagger on dev"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFpmjKgxS6dZ",
        "outputId": "ea57bbd1-2ab0-4728-860f-a0e7effc9f5b"
      },
      "source": [
        "accuracy(tagger, dev_data)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8845684287632768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojhFtVdspzNu"
      },
      "source": [
        "# Parser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deViF7R3S6dZ"
      },
      "source": [
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import tqdm as tqdm\n",
        "import time\n",
        "\n",
        "SAVE = True \n",
        "\n",
        "LR = 1e-3\n",
        "BATCH_SIZE = 100\n",
        "EPOCHS = 6\n",
        "\n",
        "LSTM_DIM = 180\n",
        "LINEAR_HIDDEN_DIM = 180\n",
        "WORD_DIM = 100\n",
        "TAG_DIM = 25\n",
        "DROPOUT_VALUE = 0.3\n",
        "\n",
        "def train_fixed_parser(train_data, n_epochs=EPOCHS, batch_size=BATCH_SIZE, lr=LR):\n",
        "\n",
        "    # Create folder for saving model\n",
        "    if SAVE and not os.path.exists(\"models\"):\n",
        "      os.makedirs(\"models\")\n",
        "\n",
        "    vocab_words, vocab_tags = make_vocabs(train_data)\n",
        "    myparser = parser.FixedWindowParser(vocab_words, vocab_tags, WORD_DIM, TAG_DIM, LSTM_DIM, LINEAR_HIDDEN_DIM, DROPOUT_VALUE)\n",
        "    myparser.model.train()\n",
        "    optimizer = optim.Adam(myparser.model.parameters(), lr=lr)\n",
        "\n",
        "    start_time = time.time()\n",
        "    best_acc = 0\n",
        "    for i in tqdm.tqdm(range(n_epochs)):\n",
        "        total_loss = 0\n",
        "        batch_nr = 0\n",
        "        \n",
        "        for words, tags, i, x, y in training_examples_parser(vocab_words, vocab_tags, train_data, myparser):\n",
        "            words = words.to(device)\n",
        "            tags = tags.to(device)\n",
        "            x = x.to(device)\n",
        "            y = y.to(device)\n",
        "            i = i.to(device)\n",
        "\n",
        "            batch_nr += 1\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            y_pred = myparser.model.forward(words[i], tags[i], x)\n",
        "            \n",
        "            loss = F.cross_entropy(y_pred, y)\n",
        "            loss.backward()\n",
        "            total_loss += loss.item()\n",
        "            optimizer.step()\n",
        "        print(\"loss: \", total_loss/batch_nr, \"time was: \", time.time() - start_time)\n",
        "        acc = uas(myparser, dev_data)\n",
        "        print(\"\", acc)\n",
        "        if SAVE and best_acc < acc:\n",
        "          best_acc = acc\n",
        "          torch.save(myparser.model.state_dict(), \"./models/lstm_parser\")\n",
        "        myparser.model.train()\n",
        "            \n",
        "    \n",
        "    return myparser"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvdWTLNXS6dZ"
      },
      "source": [
        "## Train parser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbEFRdpES6dZ",
        "outputId": "cb562518-d860-483f-f3fa-b0e0fdbce174"
      },
      "source": [
        "import os\n",
        "myparser = train_fixed_parser(train_data)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "loss:  0.3845988561939882 time was:  538.7620625495911\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/syntax_parser.py:98: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  pred = torch.nn.functional.log_softmax(pred)\n",
            "\n",
            "\n",
            "100%|██████████| 1/1 [14:19<00:00, 859.56s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            " 0.8024105654571099\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEkbfFmZorp1"
      },
      "source": [
        "## Load trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FgmNOk_nGhO"
      },
      "source": [
        "vocab_words, vocab_tags = make_vocabs(train_data)\n",
        "loaded_parser = parser.FixedWindowParser(vocab_words, vocab_tags)\n",
        "loaded_parser.model.load_state_dict(torch.load(\"./models/lstm_parser\"))\n",
        "loaded_parser.model = loaded_parser.model.to(device)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEYqT8jJo8hQ"
      },
      "source": [
        "## Eval on dev with gold tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRFYUp1VS6da",
        "outputId": "ab2993f6-85b1-4035-8509-a456100f6287"
      },
      "source": [
        "uas(loaded_parser, dev_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/syntax_parser.py:98: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  pred = torch.nn.functional.log_softmax(pred)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxuIFsK7o_7z"
      },
      "source": [
        "## Eval on test with gold tags"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIJCI76-S6da"
      },
      "source": [
        "uas(loaded_parser, test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzUx0JQiS6db"
      },
      "source": [
        "## Eval on dev with predicted tags "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4cAMFggS6db"
      },
      "source": [
        "def calc_uas_with_tagger_preds(tagger, parser, data):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    new_data = []\n",
        "    for sent in data:\n",
        "        pred_tags = tagger.predict(sent)\n",
        "    \n",
        "        # Replace gold tags with predicted\n",
        "        for i , (_, tag) in enumerate(pred_tags):\n",
        "            sent[i] = (sent[i][0], tag, sent[i][2])\n",
        "        new_data.append(sent)\n",
        "        \n",
        "    return uas(parser, new_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_BosZ5QUS6db"
      },
      "source": [
        "calc_uas_with_tagger_preds(tagger, parser, dev_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC_GU87US6db"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Y-w2et_S6db"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q97rhj9nWOr"
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    }
  ]
}