{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ygrwIIZMS6dT"
   },
   "source": [
    "# Dependency parsing baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z0Cw9eF2S6dW"
   },
   "source": [
    "\n",
    "Dependency parsing is the task of mapping a sentence to a formal representation of its syntactic structure in the form of a dependency tree, which consists of directed arcs between individual words (tokens). Here we will implement a dependency parser baseline based on the arc-standard algorithm and the fixed-window model that we implemented in Lab L3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0G66EDCpWYh"
   },
   "source": [
    "### Download neccessary python files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5P03qH_bS8y8"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/batchify.py\n",
    "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/create_vocab.py\n",
    "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/data_handling.py\n",
    "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/syntax_parser.py\n",
    "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/projectivize.py\n",
    "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/taggers.py\n",
    "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/uas.py\n",
    "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/window_models.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XE1gR7X_S6dX"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JUObqPhtS6dX"
   },
   "outputs": [],
   "source": [
    "from batchify import *\n",
    "from create_vocab import *\n",
    "from data_handling import *\n",
    "import syntax_parser as parser \n",
    "from projectivize import *\n",
    "from uas import *\n",
    "from window_models import *\n",
    "from taggers import *\n",
    "import importlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "6KGa8T2vS6dX"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hx-dccpMS6dX",
    "outputId": "250540e2-568c-4a63-8881-38bc2e99b27c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "am2_wdxqS6dY"
   },
   "source": [
    "## Prepare data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCBNkXn8pRWP"
   },
   "source": [
    "### Download data files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JD1e_hg6Tr28"
   },
   "outputs": [],
   "source": [
    "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/data/en_gum-ud-dev-projectivized.conllu\n",
    "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/data/en_gum-ud-train-projectivized.conllu\n",
    "!wget https://raw.githubusercontent.com/hugocedervall/nlp-project/main/data/en_gum-ud-test-projectivized.conllu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TaBlhMVUS6dY"
   },
   "outputs": [],
   "source": [
    "train_data = Dataset('data/en_gum-ud-train-projectivized.conllu')\n",
    "dev_data = Dataset('data/en_gum-ud-dev-projectivized.conllu')\n",
    "test_data = Dataset('data/en_gum-ud-test-projectivized.conllu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LpLw_2wHpq-o"
   },
   "source": [
    "# Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_t4pmUeuS6dY"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def train_fixed_window(train_data, n_epochs=1, batch_size=100, lr=1e-2):\n",
    "    vocab_words, vocab_tags = make_vocabs(train_data)\n",
    "    tagger = FixedWindowTagger(vocab_words, vocab_tags, len(vocab_tags))\n",
    "    \n",
    "    optimizer = optim.Adam(tagger.model.parameters(), lr=lr)\n",
    "    for i in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        batch_nr = 0\n",
    "        for x, y in training_examples_tagger(vocab_words, vocab_tags, train_data, tagger):\n",
    "            batch_nr += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = tagger.model.forward(x)\n",
    "            \n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            if batch_nr % 100 == 1:\n",
    "                print(total_loss/batch_nr)\n",
    "                #pass\n",
    "    return tagger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lzAELj15S6dY"
   },
   "source": [
    "## Train tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LWBH7yLWS6dY",
    "outputId": "9ab66171-c03f-4bec-cc01-d1b124df661a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9646172523498535\n",
      "1.073240417212543\n",
      "0.7750730240967736\n",
      "0.6449551091736734\n",
      "0.570190991063665\n",
      "0.5248511874985077\n",
      "0.4928285411486213\n",
      "0.47443602890966624\n",
      "0.4532936280325855\n"
     ]
    }
   ],
   "source": [
    "tagger = train_fixed_window(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nI0pJ_DFpgCw"
   },
   "source": [
    "## Eval tagger on dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QFpmjKgxS6dZ",
    "outputId": "ea57bbd1-2ab0-4728-860f-a0e7effc9f5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8816994261994873"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(tagger, dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ojhFtVdspzNu"
   },
   "source": [
    "# Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "deViF7R3S6dZ"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import tqdm as tqdm\n",
    "import time\n",
    "\n",
    "SAVE = True \n",
    "\n",
    "LR = 1e-3\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 6\n",
    "\n",
    "LSTM_DIM = 180\n",
    "LINEAR_HIDDEN_DIM = 180\n",
    "WORD_DIM = 100\n",
    "TAG_DIM = 25\n",
    "DROPOUT_VALUE = 0.3\n",
    "\n",
    "def train_fixed_parser(train_data, n_epochs=EPOCHS, batch_size=BATCH_SIZE, lr=LR):\n",
    "\n",
    "    # Create folder for saving model\n",
    "    if SAVE and not os.path.exists(\"models\"):\n",
    "      os.makedirs(\"models\")\n",
    "\n",
    "    vocab_words, vocab_tags = make_vocabs(train_data)\n",
    "    myparser = parser.FixedWindowParser(vocab_words, vocab_tags, WORD_DIM, TAG_DIM, LSTM_DIM, LINEAR_HIDDEN_DIM, DROPOUT_VALUE)\n",
    "    myparser.model.train()\n",
    "    optimizer = optim.Adam(myparser.model.parameters(), lr=lr)\n",
    "\n",
    "    start_time = time.time()\n",
    "    best_acc = 0\n",
    "    for i in tqdm.tqdm(range(n_epochs)):\n",
    "        total_loss = 0\n",
    "        batch_nr = 0\n",
    "        \n",
    "        for words, tags, i, x, y in training_examples_parser(vocab_words, vocab_tags, train_data, myparser):\n",
    "            words = words.to(device)\n",
    "            tags = tags.to(device)\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            i = i.to(device)\n",
    "\n",
    "            batch_nr += 1\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            y_pred = myparser.model.forward(words[i], tags[i], x)\n",
    "            \n",
    "            loss = F.cross_entropy(y_pred, y)\n",
    "            loss.backward()\n",
    "            total_loss += loss.item()\n",
    "            optimizer.step()\n",
    "        print(\"loss: \", total_loss/batch_nr, \"time was: \", time.time() - start_time)\n",
    "        acc = uas(myparser, dev_data)\n",
    "        print(\"\", acc)\n",
    "        if SAVE and best_acc < acc:\n",
    "          best_acc = acc\n",
    "          torch.save(myparser.model.state_dict(), \"./models/lstm_parser\")\n",
    "        myparser.model.train()\n",
    "            \n",
    "    \n",
    "    return myparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZvdWTLNXS6dZ"
   },
   "source": [
    "## Train parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbEFRdpES6dZ",
    "outputId": "cb562518-d860-483f-f3fa-b0e0fdbce174"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  0.3870662623013759 time was:  135.02782893180847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/git/nlp-project/syntax_parser.py:98: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred = torch.nn.functional.log_softmax(pred)\n",
      " 17%|█▋        | 1/6 [03:49<19:07, 229.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.8006154635209642\n",
      "loss:  0.23430996226512732 time was:  361.3182520866394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 2/6 [07:35<15:13, 228.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.8300423131170663\n",
      "loss:  0.16593136837601055 time was:  591.2211616039276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 3/6 [11:25<11:27, 229.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.8331196307218874\n",
      "loss:  0.12016238521166418 time was:  820.3819451332092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 4/6 [15:16<07:38, 229.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.8377997179125529\n",
      "loss:  0.09332666659199107 time was:  1049.4799551963806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 5/6 [19:05<03:49, 229.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.837222720861649\n",
      "loss:  0.07550786692880988 time was:  1278.283739566803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [22:52<00:00, 228.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.8481215540453905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "myparser = train_fixed_parser(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nEkbfFmZorp1"
   },
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4FgmNOk_nGhO"
   },
   "outputs": [],
   "source": [
    "vocab_words, vocab_tags = make_vocabs(train_data)\n",
    "loaded_parser = parser.FixedWindowParser(vocab_words, vocab_tags)\n",
    "loaded_parser.model.load_state_dict(torch.load(\"./models/lstm_parser\"))\n",
    "loaded_parser.model = loaded_parser.model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEYqT8jJo8hQ"
   },
   "source": [
    "## Eval on dev with gold tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MRFYUp1VS6da",
    "outputId": "ab2993f6-85b1-4035-8509-a456100f6287"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8492114373637646"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uas(loaded_parser, dev_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GxuIFsK7o_7z"
   },
   "source": [
    "## Eval on test with gold tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ZIJCI76-S6da"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8410146929549165"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uas(loaded_parser, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KzUx0JQiS6db"
   },
   "source": [
    "## Eval on dev with predicted tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "a4cAMFggS6db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 3070\n"
     ]
    }
   ],
   "source": [
    "from tagger_lstm import *\n",
    "tagger = get_saved_tagger().to(device)\n",
    "\n",
    "#test_loss, test_acc = evaluate(tagger, criterion, TAG_PAD_IDX, test_data)\n",
    "#print(f\"{test_acc*100:.3f} %\")\n",
    "\n",
    "vocab_words, vocab_tags = make_vocabs(train_data)\n",
    "def calc_uas_with_tagger_preds(tagger, parser, data):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    new_data = []\n",
    "    for sent in data:\n",
    "        words = sent2id(sent)\n",
    "        pred_tags = predict_tags(tagger, words, vocab_tags)\n",
    "    \n",
    "        # Replace gold tags with predicted\n",
    "        for i , tag in enumerate(pred_tags):\n",
    "            sent[i] = (sent[i][0], tag, sent[i][2])\n",
    "        new_data.append(sent)\n",
    "        \n",
    "    return uas(parser, new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_BosZ5QUS6db"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/benjamin/git/nlp-project/syntax_parser.py:98: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  pred = torch.nn.functional.log_softmax(pred)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7809975637902296"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_uas_with_tagger_preds(tagger, loaded_parser, dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tC_GU87US6db"
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Y-w2et_S6db"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "8q97rhj9nWOr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "I0G66EDCpWYh",
    "XE1gR7X_S6dX",
    "LpLw_2wHpq-o",
    "lzAELj15S6dY",
    "nI0pJ_DFpgCw",
    "GxuIFsK7o_7z",
    "KzUx0JQiS6db"
   ],
   "name": "Classifierdeluxe.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
